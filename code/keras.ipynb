{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Multiclassification with Keras: Planet understanding the amazon from space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se encuentra el código del modelo realizado utilizando las funciones de la librería Keras de Tensorflow. Primero se han procesado y preparado los datos. Despues, se ha definido el arquitectura que va a tener el modelo. A continuación, se ha entrenado el modelo con nuestro dataset. Y, por último se ha realizado la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3892,
     "status": "ok",
     "timestamp": 1650467905917,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "1EW5zYWHE-He"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "#keras.__version__\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "#import cv2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.applications import resnet\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han tenido bastantes problemas a la hora de procesar los datos debido a como estaban estructurados y porque nosotros teníamos un problema de multiclasificación. \n",
    "\n",
    "Como se ha comentado anteriormente en el análisis exploratorio, se tenía un csv que contenía una columna con el nombre de las imágenes y otra con los levels. \n",
    "\n",
    "Para adaptar las especificaciones de los argumentos de la función de Keras que generaba y procesaba \n",
    "**(train_datagen.flow_from_dataframe)** se ha tenido que cambiar el csv de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/csv_tags/train_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tags'] = train['tags'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = [\n",
    "    \"agriculture\",\n",
    "    \"artisinal_mine\",\n",
    "    \"bare_ground\",\n",
    "    \"blooming\",\n",
    "    \"blow_down\",\n",
    "    \"clear\",\n",
    "    \"cloudy\",\n",
    "    \"conventional_mine\",\n",
    "    \"cultivation\",\n",
    "    \"habitation\",\n",
    "    \"haze\",\n",
    "    \"partly_cloudy\",\n",
    "    \"primary\",\n",
    "    \"road\",\n",
    "    \"selective_logging\",\n",
    "    \"slash_burn\",\n",
    "    \"water\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar(df,TAGS):\n",
    "    for i in range(len(df)):\n",
    "        tags = df.iloc[i,1]\n",
    "        for t in tags:\n",
    "            train[t][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprobar(train,TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train.sample(frac=0.8, random_state=25)\n",
    "validating_data = train.drop(training_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de todo este procesamiento, da error cuando se ejecuta las funciones de Keras para procesar y generar los datos. El código era el siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` from keras.preprocessing.image import ImageDataGenerator```\n",
    "\n",
    "```train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')```\n",
    "\n",
    "```# Note that the validation data should not be augmented!```\n",
    "```test_datagen = ImageDataGenerator(rescale=1./255)```\n",
    "\n",
    "```train_generator = train_datagen.flow_from_dataframe(\n",
    "        training_data,\n",
    "        path_train,\n",
    "        x_col='image_name', y_col=TAGS,\n",
    "        # This is the target directory\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='multi_output')```\n",
    "\n",
    "```validation_generator = test_datagen.flow_from_dataframe(\n",
    "        validating_data,\n",
    "        path_train,\n",
    "        x_col='image_name', y_col=TAGS,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='multi_output')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se habia intentado guardar las imágenes en carpetas según sus respectivos labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```path_validation =\"../data/validation_fotos\" ```\n",
    "\n",
    "```path_train =\"../data/train_fotos\" ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_en_carpetas(path,df):\n",
    "    l2 = []\n",
    "    for foto,label in df.values:\n",
    "        path_fotos=\"../data/train_jpg\"\n",
    "        for l in label:\n",
    "            if not os.path.exists(f\"{path}/{l}\"): os.mkdir(f\"{path}/{l}\")\n",
    "            if not os.path.exists( f\"{path_train}/{foto}\"): l2.append(foto)\n",
    "      #shutil.move(f\"{path_fotos}/{foto}.jpg\", f\"{path}/{foto}.jpg\")\n",
    "      #if os.path.exists(f\"{path}/{foto}\"): print(\"bien!\")\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```fotos_no1 = guardar_en_carpetas(path_validation,validating_data)```\n",
    "\n",
    "```fotos_no2 = guardar_en_carpetas(path_train,training_data)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tampoco en este caso hemos conseguido que funcionara el código de Keras adaptado para que coja las imágenes desde el directorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final, se decidió que en lugar de procesar imágenes, se procesaría los vectores de las imágenes. Para la variable de y_train se ha definido con label_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x_train = \"../data/x_train.npy\"\n",
    "path_y_train = \"../data/y_train.npy\"\n",
    "\n",
    "if not os.path.exists(path_x_train) and not os.path.exists(path_y_train):\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    \n",
    "    df_train = pd.read_csv('../data/csv_tags/train_v2.csv')\n",
    "    \n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "    \n",
    "    label_map = {l: i for i, l in enumerate(labels)}\n",
    "    inv_label_map = {i: l for l, i in label_map.items()}\n",
    "    \n",
    "    for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "        img = cv2.imread('../data/train-jpg/{}.jpg'.format(f))\n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1 \n",
    "        x_train.append(cv2.resize(img, (32, 32)))\n",
    "        y_train.append(targets)\n",
    "        \n",
    "    y_train = np.array(y_train, np.uint8)\n",
    "    x_train = np.array(x_train, np.float16) / 255.\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    with open(path_x_train, 'wb') as f:\n",
    "        np.save(f, x_train)\n",
    "    with open(path_y_train, 'wb') as f:\n",
    "        np.save(f, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga los array de y_train y x_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/x_train.npy', 'rb') as f:\n",
    "    x_train = np.load(f)\n",
    "with open('../data/y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4119, 0.4353, 0.3765],\n",
       "         [0.408 , 0.4353, 0.3687],\n",
       "         [0.4158, 0.4392, 0.3804],\n",
       "         ...,\n",
       "         [0.392 , 0.4392, 0.3647],\n",
       "         [0.4   , 0.4236, 0.357 ],\n",
       "         [0.4   , 0.4197, 0.357 ]],\n",
       "\n",
       "        [[0.408 , 0.4158, 0.3608],\n",
       "         [0.4038, 0.4392, 0.353 ],\n",
       "         [0.4038, 0.4314, 0.357 ],\n",
       "         ...,\n",
       "         [0.4119, 0.443 , 0.349 ],\n",
       "         [0.396 , 0.4197, 0.3372],\n",
       "         [0.392 , 0.4197, 0.3372]],\n",
       "\n",
       "        [[0.4   , 0.4236, 0.3608],\n",
       "         [0.4038, 0.4236, 0.357 ],\n",
       "         [0.4119, 0.4236, 0.349 ],\n",
       "         ...,\n",
       "         [0.4   , 0.4197, 0.353 ],\n",
       "         [0.4038, 0.4275, 0.3452],\n",
       "         [0.3882, 0.4119, 0.349 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4119, 0.4275, 0.357 ],\n",
       "         [0.408 , 0.4197, 0.3687],\n",
       "         [0.4197, 0.4392, 0.3687],\n",
       "         ...,\n",
       "         [0.4158, 0.4314, 0.3647],\n",
       "         [0.4038, 0.4314, 0.353 ],\n",
       "         [0.408 , 0.4314, 0.3726]],\n",
       "\n",
       "        [[0.4119, 0.4314, 0.3608],\n",
       "         [0.4158, 0.4314, 0.3726],\n",
       "         [0.4197, 0.447 , 0.3804],\n",
       "         ...,\n",
       "         [0.4197, 0.443 , 0.3804],\n",
       "         [0.4   , 0.4275, 0.357 ],\n",
       "         [0.4119, 0.4353, 0.3647]],\n",
       "\n",
       "        [[0.4197, 0.447 , 0.3843],\n",
       "         [0.4119, 0.4353, 0.3608],\n",
       "         [0.4197, 0.443 , 0.3726],\n",
       "         ...,\n",
       "         [0.4158, 0.4392, 0.357 ],\n",
       "         [0.4119, 0.447 , 0.3687],\n",
       "         [0.396 , 0.4158, 0.3293]]],\n",
       "\n",
       "\n",
       "       [[[0.251 , 0.2783, 0.2354],\n",
       "         [0.204 , 0.255 , 0.204 ],\n",
       "         [0.255 , 0.3098, 0.255 ],\n",
       "         ...,\n",
       "         [0.2235, 0.2471, 0.2   ],\n",
       "         [0.2783, 0.353 , 0.2903],\n",
       "         [0.2588, 0.2825, 0.2471]],\n",
       "\n",
       "        [[0.2588, 0.3098, 0.2705],\n",
       "         [0.2588, 0.2903, 0.2432],\n",
       "         [0.2432, 0.2903, 0.2471],\n",
       "         ...,\n",
       "         [0.2471, 0.255 , 0.2196],\n",
       "         [0.2627, 0.306 , 0.2744],\n",
       "         [0.255 , 0.3452, 0.2783]],\n",
       "\n",
       "        [[0.251 , 0.2942, 0.251 ],\n",
       "         [0.2705, 0.3215, 0.2744],\n",
       "         [0.255 , 0.298 , 0.2588],\n",
       "         ...,\n",
       "         [0.2313, 0.2705, 0.2235],\n",
       "         [0.255 , 0.2666, 0.2354],\n",
       "         [0.2588, 0.3215, 0.2666]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3215, 0.4353, 0.4119],\n",
       "         [0.3176, 0.443 , 0.4158],\n",
       "         [0.3098, 0.396 , 0.3687],\n",
       "         ...,\n",
       "         [0.251 , 0.2744, 0.2274],\n",
       "         [0.2432, 0.2864, 0.2274],\n",
       "         [0.255 , 0.2783, 0.2235]],\n",
       "\n",
       "        [[0.3254, 0.4392, 0.396 ],\n",
       "         [0.3176, 0.4197, 0.396 ],\n",
       "         [0.3215, 0.4197, 0.3726],\n",
       "         ...,\n",
       "         [0.2354, 0.2313, 0.2   ],\n",
       "         [0.2471, 0.2744, 0.2432],\n",
       "         [0.2196, 0.2588, 0.2157]],\n",
       "\n",
       "        [[0.3215, 0.4275, 0.396 ],\n",
       "         [0.3372, 0.4275, 0.392 ],\n",
       "         [0.3137, 0.4197, 0.392 ],\n",
       "         ...,\n",
       "         [0.2471, 0.2354, 0.2   ],\n",
       "         [0.2627, 0.306 , 0.2471],\n",
       "         [0.251 , 0.2942, 0.2666]]],\n",
       "\n",
       "\n",
       "       [[[0.2274, 0.2313, 0.1804],\n",
       "         [0.2274, 0.2079, 0.1608],\n",
       "         [0.2196, 0.2393, 0.1804],\n",
       "         ...,\n",
       "         [0.2235, 0.2196, 0.1608],\n",
       "         [0.2274, 0.2313, 0.1569],\n",
       "         [0.2313, 0.2588, 0.196 ]],\n",
       "\n",
       "        [[0.2157, 0.2274, 0.1765],\n",
       "         [0.2235, 0.2354, 0.1882],\n",
       "         [0.2393, 0.255 , 0.2   ],\n",
       "         ...,\n",
       "         [0.2196, 0.2471, 0.1921],\n",
       "         [0.2196, 0.2432, 0.1765],\n",
       "         [0.2235, 0.2274, 0.1686]],\n",
       "\n",
       "        [[0.2196, 0.2354, 0.1686],\n",
       "         [0.2157, 0.2313, 0.1765],\n",
       "         [0.2196, 0.2235, 0.1569],\n",
       "         ...,\n",
       "         [0.2313, 0.2393, 0.1843],\n",
       "         [0.2235, 0.2313, 0.196 ],\n",
       "         [0.2274, 0.2393, 0.1686]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.255 , 0.2744, 0.196 ],\n",
       "         [0.2313, 0.2235, 0.1686],\n",
       "         [0.2432, 0.2471, 0.1765],\n",
       "         ...,\n",
       "         [0.2196, 0.2118, 0.1608],\n",
       "         [0.2393, 0.2588, 0.2   ],\n",
       "         [0.2235, 0.2274, 0.1726]],\n",
       "\n",
       "        [[0.2196, 0.2354, 0.1843],\n",
       "         [0.2196, 0.2235, 0.1569],\n",
       "         [0.2432, 0.2235, 0.1882],\n",
       "         ...,\n",
       "         [0.2274, 0.2079, 0.149 ],\n",
       "         [0.2196, 0.2118, 0.1451],\n",
       "         [0.2196, 0.2313, 0.1608]],\n",
       "\n",
       "        [[0.2157, 0.2235, 0.1726],\n",
       "         [0.251 , 0.2627, 0.2   ],\n",
       "         [0.2157, 0.204 , 0.149 ],\n",
       "         ...,\n",
       "         [0.2393, 0.2354, 0.1804],\n",
       "         [0.2393, 0.2354, 0.1882],\n",
       "         [0.2235, 0.2   , 0.1372]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.2157, 0.349 , 0.4158],\n",
       "         [0.1608, 0.2744, 0.3254],\n",
       "         [0.1294, 0.2471, 0.302 ],\n",
       "         ...,\n",
       "         [0.1255, 0.2354, 0.3176],\n",
       "         [0.1098, 0.2274, 0.298 ],\n",
       "         [0.0706, 0.153 , 0.2196]],\n",
       "\n",
       "        [[0.204 , 0.3608, 0.4197],\n",
       "         [0.153 , 0.2666, 0.3254],\n",
       "         [0.153 , 0.2783, 0.3215],\n",
       "         ...,\n",
       "         [0.1608, 0.2744, 0.353 ],\n",
       "         [0.0941, 0.2079, 0.2705],\n",
       "         [0.0902, 0.2   , 0.2627]],\n",
       "\n",
       "        [[0.2235, 0.349 , 0.4392],\n",
       "         [0.1569, 0.2627, 0.3293],\n",
       "         [0.1608, 0.2783, 0.3372],\n",
       "         ...,\n",
       "         [0.098 , 0.1882, 0.2588],\n",
       "         [0.102 , 0.196 , 0.251 ],\n",
       "         [0.102 , 0.204 , 0.2783]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1216, 0.2235, 0.2744],\n",
       "         [0.1294, 0.2313, 0.2864],\n",
       "         [0.1333, 0.2274, 0.2864],\n",
       "         ...,\n",
       "         [0.1216, 0.2235, 0.2825],\n",
       "         [0.1098, 0.2235, 0.2744],\n",
       "         [0.1333, 0.2471, 0.3098]],\n",
       "\n",
       "        [[0.1333, 0.2313, 0.2903],\n",
       "         [0.1177, 0.2157, 0.2744],\n",
       "         [0.1333, 0.2274, 0.2744],\n",
       "         ...,\n",
       "         [0.1216, 0.2274, 0.2903],\n",
       "         [0.1216, 0.2393, 0.306 ],\n",
       "         [0.1059, 0.2   , 0.255 ]],\n",
       "\n",
       "        [[0.1333, 0.2354, 0.2864],\n",
       "         [0.1216, 0.2196, 0.2744],\n",
       "         [0.1255, 0.2157, 0.2783],\n",
       "         ...,\n",
       "         [0.0902, 0.204 , 0.2471],\n",
       "         [0.0902, 0.1726, 0.2313],\n",
       "         [0.102 , 0.2   , 0.2471]]],\n",
       "\n",
       "\n",
       "       [[[0.4158, 0.5176, 0.533 ],\n",
       "         [0.396 , 0.498 , 0.498 ],\n",
       "         [0.408 , 0.5137, 0.502 ],\n",
       "         ...,\n",
       "         [0.451 , 0.545 , 0.5845],\n",
       "         [0.447 , 0.545 , 0.5728],\n",
       "         [0.408 , 0.498 , 0.5137]],\n",
       "\n",
       "        [[0.4197, 0.506 , 0.5215],\n",
       "         [0.4119, 0.5137, 0.5137],\n",
       "         [0.4197, 0.502 , 0.533 ],\n",
       "         ...,\n",
       "         [0.4   , 0.4902, 0.5176],\n",
       "         [0.4746, 0.565 , 0.604 ],\n",
       "         [0.4353, 0.533 , 0.5527]],\n",
       "\n",
       "        [[0.4038, 0.51  , 0.5137],\n",
       "         [0.408 , 0.506 , 0.5254],\n",
       "         [0.4158, 0.51  , 0.5215],\n",
       "         ...,\n",
       "         [0.4666, 0.569 , 0.6   ],\n",
       "         [0.4392, 0.5293, 0.5527],\n",
       "         [0.451 , 0.5566, 0.5845]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.396 , 0.4941, 0.506 ],\n",
       "         [0.4   , 0.4941, 0.51  ],\n",
       "         [0.408 , 0.502 , 0.5137],\n",
       "         ...,\n",
       "         [0.396 , 0.4902, 0.502 ],\n",
       "         [0.4038, 0.4863, 0.5137],\n",
       "         [0.4119, 0.4941, 0.5215]],\n",
       "\n",
       "        [[0.4038, 0.502 , 0.51  ],\n",
       "         [0.408 , 0.51  , 0.506 ],\n",
       "         [0.408 , 0.502 , 0.5137],\n",
       "         ...,\n",
       "         [0.4158, 0.506 , 0.5254],\n",
       "         [0.392 , 0.4863, 0.498 ],\n",
       "         [0.4038, 0.4941, 0.502 ]],\n",
       "\n",
       "        [[0.408 , 0.5215, 0.5254],\n",
       "         [0.4   , 0.51  , 0.5293],\n",
       "         [0.51  , 0.6235, 0.686 ],\n",
       "         ...,\n",
       "         [0.408 , 0.502 , 0.5176],\n",
       "         [0.396 , 0.4902, 0.4941],\n",
       "         [0.396 , 0.4785, 0.4824]]],\n",
       "\n",
       "\n",
       "       [[[0.2903, 0.353 , 0.298 ],\n",
       "         [0.2864, 0.3215, 0.2864],\n",
       "         [0.2471, 0.2627, 0.2196],\n",
       "         ...,\n",
       "         [0.353 , 0.4197, 0.4785],\n",
       "         [0.2393, 0.255 , 0.2196],\n",
       "         [0.2903, 0.3452, 0.3215]],\n",
       "\n",
       "        [[0.2864, 0.353 , 0.2783],\n",
       "         [0.2666, 0.3137, 0.2705],\n",
       "         [0.302 , 0.3452, 0.3176],\n",
       "         ...,\n",
       "         [0.3765, 0.4392, 0.506 ],\n",
       "         [0.2354, 0.2705, 0.2274],\n",
       "         [0.3333, 0.392 , 0.4   ]],\n",
       "\n",
       "        [[0.2903, 0.357 , 0.3215],\n",
       "         [0.306 , 0.3647, 0.349 ],\n",
       "         [0.302 , 0.341 , 0.3215],\n",
       "         ...,\n",
       "         [0.306 , 0.3726, 0.341 ],\n",
       "         [0.2825, 0.3333, 0.302 ],\n",
       "         [0.349 , 0.4158, 0.4392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2666, 0.2825, 0.255 ],\n",
       "         [0.2432, 0.2627, 0.2157],\n",
       "         [0.251 , 0.2705, 0.2393],\n",
       "         ...,\n",
       "         [0.255 , 0.2666, 0.2274],\n",
       "         [0.2393, 0.2627, 0.2274],\n",
       "         [0.2705, 0.2864, 0.2471]],\n",
       "\n",
       "        [[0.2588, 0.2903, 0.255 ],\n",
       "         [0.2471, 0.2705, 0.2079],\n",
       "         [0.2393, 0.2471, 0.2118],\n",
       "         ...,\n",
       "         [0.2627, 0.302 , 0.2627],\n",
       "         [0.2627, 0.2864, 0.251 ],\n",
       "         [0.2744, 0.3176, 0.2744]],\n",
       "\n",
       "        [[0.251 , 0.2783, 0.2313],\n",
       "         [0.2432, 0.2627, 0.2157],\n",
       "         [0.2588, 0.2825, 0.2393],\n",
       "         ...,\n",
       "         [0.2705, 0.2825, 0.2393],\n",
       "         [0.2666, 0.2783, 0.251 ],\n",
       "         [0.2705, 0.298 , 0.251 ]]]], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, se separa los datos en train, test y validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29144 7287 4048\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train) , len(x_val) , len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura del modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo se ha realizado a partir de un modelo base de ResNet50. A ese modelo se le ha añadido una capa de Flatten y dos de Dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos probado dos input_size (82,82) y (32,32). Entendemos que tendrá que dar mejor resultado el size más pequeño ya que el modelo aprende más facil. Aun asi, los resultados no lo reflejan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3207,
     "status": "ok",
     "timestamp": 1650469741430,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "PzKdZKiLE-Hl",
    "outputId": "6f1e8621-c825-4e93-a743-f0942779604f"
   },
   "outputs": [],
   "source": [
    "conv_base = resnet.ResNet50(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(82, 82, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2605,
     "status": "ok",
     "timestamp": 1650469779806,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "FWeF4XTmE-Hn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4f44d77b-65bd-4420-878c-dc0d70ec9543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1650469806195,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "HYCrrR-EE-H0"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#model.add(BatchNormalization(input_shape=(82, 82,3)))\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(17, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccaJb_CKE-H2"
   },
   "source": [
    "This is what our model looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1650469809200,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "XLrAHB6uE-H3",
    "outputId": "0588b6d3-98ff-4f4a-c47d-70af318cc920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 17)                4369      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,116,625\n",
      "Trainable params: 24,063,505\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1650469895325,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "62oFeUXLE-H5",
    "outputId": "a077c2c3-3d1d-434a-be9e-71940c0919a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 216\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1650469903696,
     "user": {
      "displayName": "Ana Blasi Sanchiz",
      "userId": "06521881660188386515"
     },
     "user_tz": -120
    },
    "id": "qbVIaOipE-H9",
    "outputId": "ed6c53b8-1779-40a5-eb3f-f7164c4f5b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar el modelo con nuestro Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha definido la variable callbacks para definir el Early Stopping y para que guarde los weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "callbacks = [history, \n",
    "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ModelCheckpoint(filepath='../data/weights.best.hdf5', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=True, mode='auto')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, es el momento de entrenar el modelo. Se ha utilizado el optamizer de Adam y al final, nos hemos quedado con un LR de 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:04:31.350457: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2351571072 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.7057\n",
      "Epoch 1: val_loss did not improve from 0.24412\n",
      "228/228 [==============================] - 576s 2s/step - loss: 0.1498 - accuracy: 0.7057 - val_loss: 0.5232 - val_accuracy: 0.0060\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.7216\n",
      "Epoch 2: val_loss did not improve from 0.24412\n",
      "228/228 [==============================] - 562s 2s/step - loss: 0.1083 - accuracy: 0.7216 - val_loss: 0.5391 - val_accuracy: 0.0587\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.7008\n",
      "Epoch 3: val_loss did not improve from 0.24412\n",
      "228/228 [==============================] - 563s 2s/step - loss: 0.1250 - accuracy: 0.7008 - val_loss: 0.3803 - val_accuracy: 0.6249\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.6958\n",
      "Epoch 4: val_loss improved from 0.24412 to 0.23743, saving model to /home/ana_blasi/notebooks/PRACTICA_IMAGE/planet-understanding-the-amazon-from-space/weights.best.hdf5\n",
      "228/228 [==============================] - 561s 2s/step - loss: 0.1063 - accuracy: 0.6958 - val_loss: 0.2374 - val_accuracy: 0.6779\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.6974\n",
      "Epoch 5: val_loss improved from 0.23743 to 0.15421, saving model to /home/ana_blasi/notebooks/PRACTICA_IMAGE/planet-understanding-the-amazon-from-space/weights.best.hdf5\n",
      "228/228 [==============================] - 559s 2s/step - loss: 0.0947 - accuracy: 0.6974 - val_loss: 0.1542 - val_accuracy: 0.6416\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.6816\n",
      "Epoch 6: val_loss improved from 0.15421 to 0.13340, saving model to /home/ana_blasi/notebooks/PRACTICA_IMAGE/planet-understanding-the-amazon-from-space/weights.best.hdf5\n",
      "228/228 [==============================] - 562s 2s/step - loss: 0.0846 - accuracy: 0.6816 - val_loss: 0.1334 - val_accuracy: 0.6151\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.6684\n",
      "Epoch 7: val_loss did not improve from 0.13340\n",
      "228/228 [==============================] - 557s 2s/step - loss: 0.0760 - accuracy: 0.6684 - val_loss: 0.2238 - val_accuracy: 0.7232\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.6771\n",
      "Epoch 8: val_loss did not improve from 0.13340\n",
      "228/228 [==============================] - 561s 2s/step - loss: 0.0679 - accuracy: 0.6771 - val_loss: 0.1894 - val_accuracy: 0.6366\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.6619\n",
      "Epoch 9: val_loss did not improve from 0.13340\n",
      "228/228 [==============================] - 557s 2s/step - loss: 0.0572 - accuracy: 0.6619 - val_loss: 0.1945 - val_accuracy: 0.5456\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe17ef02610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "d-DCSYIYE-IE",
    "outputId": "e8a18965-f877-4c6e-bb0e-c3bc52d910f7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "98DxQlFLE-IX",
    "outputId": "de3ab007-e8df-40db-bac6-abda0d94f38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 - 14s - loss: 0.1945 - accuracy: 0.5482 - 14s/epoch - 109ms/step\n",
      "test acc: 0.5481719374656677\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_yFJRLqFM1c"
   },
   "source": [
    "# Entrenar el modelo con size (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/x_train_32.npy', 'rb') as f:\n",
    "    x_train = np.load(f)\n",
    "with open('../data/y_train_32.npy', 'rb') as f:\n",
    "    y_train = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "callbacks = [history, \n",
    "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ModelCheckpoint(filepath='../data/weights32.best.hdf5', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=True, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = resnet.ResNet50(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "#model.add(BatchNormalization(input_shape=(82, 82,3)))\n",
    "model2.add(conv_base)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(256, activation='relu'))\n",
    "model2.add(layers.Dense(17, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model2.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model2.evaluate(x_test, y_test, verbose=2)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Como conclusiones,"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de 9_IMAGE_Pretrained-convnet.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
